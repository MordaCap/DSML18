{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['datetime'] =  pd.to_datetime(df['datetime'])\n",
    "df = df.drop(['registered', 'casual'], axis=1)\n",
    "df = df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Немного посмотрели предварительно на все int cols, заметили магией, что можно их в onehot пихнуть (просто подумали, а какие из них категории, а какие не торт)\n",
    "### Стоит сказать, что onehot из sklearn мне нравится меньше dummes из pd, но справедливости ради нужно уметь работать со спарсами, память-***мять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "y = df['count']\n",
    "x = df.drop('count', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51131.67176974893"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "mean_squared_error(y_true=y_test, y_pred=model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37779.59990125536"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "mean_squared_error(y_true=y_test, y_pred=model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonCatCols = ['temp', 'atemp','humidity', 'windspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "/home/morda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "enc.fit(df[['season', 'holiday', 'workingday', 'weather']])\n",
    "\n",
    "x_train_oneHot = enc.transform(x_train[['season', 'holiday', 'workingday', 'weather']])\n",
    "x_test_oneHot = enc.transform(x_test[['season', 'holiday', 'workingday', 'weather']])\n",
    "x_train_oneHot = hstack((x_train_oneHot, x_train[nonCatCols].as_matrix()))\n",
    "x_test_oneHot = hstack((x_test_oneHot, x_test[nonCatCols].as_matrix()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================\n",
    "\n",
    "# onehot by dummes + add cat feature daytime \n",
    "00:00-04:00 - ночь;\n",
    "04:00-12:00 - утро;\n",
    "12:00-17:00 - день;\n",
    "17:00-00:00 - вечер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.between_time('00:00','04:00').index, 'daytime'] = 1\n",
    "df.loc[df.between_time('04:00','12:00').index, 'daytime'] = 2\n",
    "df.loc[df.between_time('12:00','17:00').index, 'daytime'] = 3\n",
    "df.loc[df.between_time('17:00','00:00').index, 'daytime'] = 4\n",
    "\n",
    "features_cat = ['season', 'holiday', 'workingday', 'daytime', 'weather']\n",
    "features_noncat = ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "for i in features_cat:\n",
    "    df[i] = df[i].astype('category')\n",
    "cat = pd.get_dummies(df[features_cat])\n",
    "noncat = df[features_noncat]\n",
    "df_cat = pd.concat([noncat,cat], axis=1)\n",
    "\n",
    "x_train_oneHot, x_test_oneHot, y_train, y_test = train_test_split(df_cat,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35205.85486834048"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(x_train_oneHot, y_train)\n",
    "\n",
    "mean_squared_error(y_true=y_test, y_pred=modelLR.predict(x_test_oneHot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29189.88453851126"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "model.fit(x_train_oneHot, y_train)\n",
    "\n",
    "mean_squared_error(y_true=y_test, y_pred=model.predict(x_test_oneHot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# го на feature_importances_ посмотрим ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.212553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.114060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.050743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.043633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.025250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.019806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.011607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance\n",
       "1     0.212553\n",
       "2     0.182922\n",
       "3     0.142314\n",
       "12    0.114060\n",
       "0     0.110592\n",
       "10    0.050743\n",
       "13    0.043633\n",
       "15    0.025250\n",
       "17    0.019806\n",
       "5     0.016725\n",
       "7     0.012894\n",
       "4     0.012685\n",
       "14    0.011878\n",
       "16    0.011607\n",
       "11    0.011496\n",
       "6     0.010442\n",
       "18    0.005849\n",
       "9     0.002464\n",
       "8     0.002038\n",
       "19    0.000048"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = model.feature_importances_\n",
    "importance = pd.DataFrame(importance, \n",
    "                          columns=[\"Importance\"])\n",
    "importance.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = [19,9,8,18]\n",
    "good = [x for x in range(20) if x not in bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29586.822053140095\n",
      "29208.306650336803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35550.278322106555"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr_new = sparse.lil_matrix(sparse.csr_matrix(x_train_oneHot)[:,[i for i in range(16) if i in good]])\n",
    "xts_new = sparse.lil_matrix(sparse.csr_matrix(x_test_oneHot)[:,[i for i in range(16) if i in good]])\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(xtr_new, y_train)\n",
    "\n",
    "print(mean_squared_error(y_true=y_test, y_pred=model.predict(xts_new)))\n",
    "\n",
    "xtr_new = sparse.lil_matrix(sparse.csr_matrix(x_train_oneHot)[:,[i for i in range(16) if i not in bad]])\n",
    "xts_new = sparse.lil_matrix(sparse.csr_matrix(x_test_oneHot)[:,[i for i in range(16) if i not in bad]])\n",
    "\n",
    "model.fit(xtr_new, y_train)\n",
    "\n",
    "print(mean_squared_error(y_true=y_test, y_pred=model.predict(xts_new)))\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(xtr_new, y_train)\n",
    "\n",
    "mean_squared_error(y_true=y_test, y_pred=modelLR.predict(xts_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну и протравим модельке из прошлого таска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18832.583515328162"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(max_depth=6,max_leaf_nodes=50)\n",
    "model.fit(xtr_new,y_train)\n",
    "\n",
    "mean_squared_error(y_true=y_test, y_pred=model.predict(xts_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Немного бэклога:\n",
    "    - LogReg просто и с onehot (mse): 51131.67 vs. 45398.20 --- (чисто из коробки очень крутой буст, просто с oneHot)\n",
    "    - DT (Ну тут можно долго играться, бустинги накрутить, данные получше повертеть с разных сторон и вообще включить кеглера, а можно просто посмотреть, как линейные регрессии проигрывают деревьям в анализе почти 80% катфитч (selfjoke Catboost)) :::: DT vs DT+OneHot (mse) : 37407.35 vs. 37913.87. Почему так? Ну какую-никакую, но importance обрезанные фичи имели. Зачем так делать? Еще один способ удалить неважный мусор и сосредоточиться на важном. Ну и т.д. \n",
    "    \n",
    "    onehot encoding отличный инструмент в различных ситуациях, не только в регресии. Позволяет алгоритмам почуствовать себя деревянными. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
